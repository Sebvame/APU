# üìö APU - Apuntes IA

**Asistente Inteligente para Consultar Apuntes Acad√©micos**

APU es una aplicaci√≥n avanzada de RAG (Retrieval-Augmented Generation) especializada en procesar y consultar apuntes de clase, documentos acad√©micos y papers de investigaci√≥n. Utiliza embeddings sem√°nticos y modelos de lenguaje locales para proporcionar respuestas precisas basadas en tus documentos.

## üåü Caracter√≠sticas Principales

- **üîç B√∫squeda Sem√°ntica Avanzada**: Encuentra informaci√≥n relevante usando similitud vectorial
- **üìÑ Procesamiento Inteligente de PDFs**: Extrae metadata espec√≠fica de apuntes de clase
- **ü§ñ RAG con Modelos Locales**: Usa Ollama para respuestas sin enviar datos a terceros
- **üåê B√∫squeda Web Opcional**: Complementa con informaci√≥n actualizada de internet
- **üìä Gesti√≥n Visual de Documentos**: Interfaz intuitiva para manejar tus archivos
- **üíæ Memoria de Conversaci√≥n**: Mantiene contexto entre preguntas
- **‚ö° Threshold Adaptativo**: Ajusta autom√°ticamente la precisi√≥n de b√∫squeda

## üõ†Ô∏è Requisitos del Sistema

- **Python**: 3.10 o superior
- **Sistema Operativo**: Windows, macOS, o Linux
- **RAM**: M√≠nimo 8GB (recomendado 16GB para modelos grandes)
- **Espacio en Disco**: Al menos 10GB libres
- **Internet**: Para descargar modelos inicialmente

## üöÄ Instalaci√≥n y Configuraci√≥n

### 1. Clonar el Repositorio

```bash
git clone <url-del-repositorio>
cd APU
```

### 2. Crear y Activar Entorno Virtual

#### En Windows (PowerShell):
```powershell
# Crear entorno virtual
python -m venv .venv

# Activar entorno virtual
.\.venv\Scripts\Activate.ps1

# Si tienes problemas de permisos, ejecuta primero:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

#### En macOS/Linux:
```bash
# Crear entorno virtual
python3 -m venv .venv

# Activar entorno virtual
source .venv/bin/activate
```

### 3. Instalar Dependencias

```bash
# Actualizar pip
pip install --upgrade pip

# Instalar dependencias principales
pip install streamlit>=1.29.0
pip install sentence-transformers>=2.2.2
pip install faiss-cpu>=1.7.4
pip install langchain>=0.1.0
pip install langchain-community>=0.0.20
pip install numpy>=1.26.0
pip install PyPDF2>=3.0.0
pip install pdfplumber>=0.10.0
pip install python-dotenv>=1.0.0
pip install requests>=2.31.0

# Dependencias opcionales para b√∫squeda web
pip install tavily-python>=0.3.0
```

### 4. Instalar y Configurar Ollama

#### Descargar Ollama:
- **Windows/macOS**: Ve a [https://ollama.ai/download](https://ollama.ai/download)
- **Linux**: 
  ```bash
  curl -fsSL https://ollama.ai/install.sh | sh
  ```

#### Iniciar Ollama:
```bash
# Iniciar servidor Ollama (mantener esta terminal abierta)
ollama serve
```

#### Descargar Modelo Recomendado:
```bash
# En otra terminal, descargar modelo (recomendado para mejor rendimiento)
ollama pull mistral:7b

# Alternativas seg√∫n tus recursos:
ollama pull llama3.1:7b     # Buen balance calidad/velocidad
ollama pull llama3.2:3b     # M√°s r√°pido, menos recursos
ollama pull phi3:7b         # Optimizado para Q&A
```

### 5. Configurar Variables de Entorno

Crea un archivo `.env` en la ra√≠z del proyecto:

```env
# Configuraci√≥n de la Aplicaci√≥n
APP_NAME=APU - Apuntes IA
APP_VERSION=1.0.0
DEBUG_MODE=False

# Configuraci√≥n Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=mistral:7b

# Configuraci√≥n de Procesamiento
CHUNK_SIZE=500
CHUNK_OVERLAP=50
MAX_SEARCH_RESULTS=8

# B√∫squeda Web (Opcional)
TAVILY_API_KEY=tu_api_key_aqui

# Configuraci√≥n UI
STREAMLIT_THEME=dark
MAX_CHAT_HISTORY=50
```

### 6. Crear Estructura de Directorios

```bash
# Los directorios se crean autom√°ticamente al ejecutar la app
# Pero puedes crearlos manualmente si lo prefieres:

mkdir -p data/documents
mkdir -p data/processed  
mkdir -p data/faiss_index
mkdir -p data/sessions
```

## ‚ñ∂Ô∏è Ejecutar la Aplicaci√≥n

### 1. Verificar que Ollama est√© ejecut√°ndose:
```bash
# En una terminal, mantener ejecutando:
ollama serve
```

### 2. Iniciar APU:
```bash
# En otra terminal, con el entorno virtual activado:
streamlit run app.py
```

### 3. Acceder a la Aplicaci√≥n:
- Abrir navegador en: **http://localhost:8502**
- La aplicaci√≥n se cargar√° autom√°ticamente

## üìñ C√≥mo Usar APU

### 1. **Cargar Documentos**

1. Ve al **sidebar** ‚Üí "üìÑ Documentos"
2. Haz clic en **"Browse files"**, alternativamente puedes arrastrar y soltar los archivos sobre la secci√≥n.
3. Selecciona tus archivos PDF (apuntes de clase, papers, etc.)
4. Presiona **"üîÑ Procesar Documnentos"**


### 2. **Realizar Consultas**

#### B√∫squeda en Documentos (por defecto):
```
¬øQu√© es una regresi√≥n lineal?
¬øQu√© es un autoencoder?
¬øQui√©n es el autor del documento de la Semana #?
Explica las diferencias entre encoder y decoder
¬øCu√°les son los tipos de autoencoders mencionados?
```

#### B√∫squeda Web (opcional):
```
Buscar en internet las √∫ltimas noticias sobre IA
Informaci√≥n actualizada sobre U-Net en 2024
Buscar web ejemplos de autoencoders recientes
```

### 3. **Funciones Avanzadas**

#### Exportar Conversaciones:
- **JSON**: Para an√°lisis posterior
- **Markdown**: Para documentaci√≥n

#### Configurar B√∫squeda:
- **Mostrar fuentes**: Ver documentos consultados
- **B√∫squeda web**: Habilitar consultas en internet
- **Limpiar conversaci√≥n**: Reiniciar contexto

### 4. **Ejemplos de Metadata Extra√≠da**

APU extrae autom√°ticamente informaci√≥n como:

```json
{
  "title": "Apuntes Semana #",
  "authors": ["Jos√© Jos√© Josares"],  
  "document_type": "class_notes",
  "course_week": 13,
  "date": "20/05/2025",
  "institution": "Instituto Tecnol√≥gico de Costa Rica",
  "topics_covered": ["Autoencoder", "U-Net", "Deep Learning"],
  "sections": ["RESPUESTAS DEL QUIZ", "REPASO", "ENCODER"],
  "quiz_questions": 4,
  "extraction_confidence": 0.85
}
```

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Cambiar Modelo de Ollama:
```bash
# Descargar modelo diferente
ollama pull llama3.1:8b

# Actualizar .env
OLLAMA_MODEL=llama3.1:8b
```

### Optimizar Rendimiento:
```env
# Para documentos largos
CHUNK_SIZE=700
CHUNK_OVERLAP=100

# Para m√°s resultados
MAX_SEARCH_RESULTS=12

# Para mejor precisi√≥n
SIMILARITY_THRESHOLD=0.2
```

### Habilitar B√∫squeda Web:
1. Obtener API key gratuita en [https://tavily.com](https://tavily.com)
2. Agregar en `.env`: `TAVILY_API_KEY=tu_api_key`
3. Activar en la interfaz: ‚òëÔ∏è "üåê Permitir b√∫squeda web"
4. Iniciar el prompt/consulta con "Busca en internet..."

## üîß Soluci√≥n de Problemas

### Error: "No se pudo conectar con Ollama"
```bash
# Verificar que Ollama est√© ejecut√°ndose
ollama serve

# Verificar conexi√≥n
curl http://localhost:11434/api/version

# Verificar modelo descargado
ollama list
```

### Error: "Timeout del modelo"
- Cambiar a un modelo m√°s r√°pido: `ollama pull llama3.2:3b`
- Aumentar timeout en `.env`: `OLLAMA_TIMEOUT=512`

### Error: "Memoria insuficiente"
- Usar modelo m√°s peque√±o: `phi3:3b` o `llama3.2:1b`
- Cerrar otras aplicaciones que consuman RAM

### Error: "No se encontraron documentos"
1. Verificar que los PDFs est√©n en `data/documents/`
2. Procesarlos usando la interfaz web
3. Verificar que el √≠ndice se haya creado en `data/faiss_index/`

### Problemas con Streamlit:
```bash
# Limpiar cach√©
streamlit cache clear

# Ejecutar en puerto diferente
streamlit run app.py --server.port 8503
```

## üìä Estad√≠sticas y Monitoreo

La aplicaci√≥n muestra en tiempo real:
- **Documentos indexados**
- **Fragmentos de texto** procesados
- **Tama√±o del √≠ndice** vectorial
- **Calidad promedio** de embeddings
- **Sesi√≥n actual** y historial

